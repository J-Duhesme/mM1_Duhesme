{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freqdicts pour dépendants ou head des lemmes pivot, sans et avec filtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ep1_s = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/dep (what is dep of pain)/dep_ep1_s.txt\"\n",
    "output_ep2_s = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/dep (what is dep of pain)/dep_ep2_s.txt\"\n",
    "output_ep3_s = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/dep (what is dep of pain)/dep_ep3_s.txt\"\n",
    "\n",
    "output_ep1_a = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/dep (what is dep of pain)/dep_ep1_a.txt\"\n",
    "output_ep2_a = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/dep (what is dep of pain)/dep_ep2_a.txt\"\n",
    "output_ep3_a = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/dep (what is dep of pain)/dep_ep3_a.txt\"\n",
    "\n",
    "output_ep1_y = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/dep (what is dep of pain)/dep_ep1_y.txt\"\n",
    "output_ep2_y = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/dep (what is dep of pain)/dep_ep2_y.txt\"\n",
    "output_ep3_y = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/dep (what is dep of pain)/dep_ep3_y.txt\"\n",
    "\n",
    "o_ep1_s = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/DEP (pain dep  of)/DEP_ep1_s.txt\"\n",
    "o_ep2_s = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/DEP (pain dep  of)/DEP_ep2_s.txt\"\n",
    "o_ep3_s = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/DEP (pain dep  of)/DEP_ep3_s.txt\"\n",
    "\n",
    "o_ep1_a = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/DEP (pain dep  of)/DEP_ep1_a.txt\"\n",
    "o_ep2_a = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/DEP (pain dep  of)/DEP_ep2_a.txt\"\n",
    "o_ep3_a = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/DEP (pain dep  of)/DEP_ep3_a.txt\"\n",
    "\n",
    "o_ep1_y = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/DEP (pain dep  of)/DEP_ep1_y.txt\"\n",
    "o_ep2_y = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/DEP (pain dep  of)/DEP_ep2_y.txt\"\n",
    "o_ep3_y = \"/home/port-pret-etu01/Documents/LATTICE/dependencies/DEP (pain dep  of)/DEP_ep3_y.txt\"\n",
    "\n",
    "\n",
    "outputs_s = [output_ep1_s, output_ep2_s, output_ep3_s] \n",
    "outputs_a = [output_ep1_a, output_ep2_a, output_ep3_a]\n",
    "outputs_y = [output_ep1_y, output_ep2_y, output_ep3_y]\n",
    "\n",
    "o_s = [o_ep1_s, o_ep2_s, o_ep3_s] \n",
    "o_a = [o_ep1_a, o_ep2_a, o_ep3_a]\n",
    "o_y = [o_ep1_y, o_ep2_y, o_ep3_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code pour tableaux sans filtre, top 10 token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import json\n",
    "\n",
    "with open(\"/home/port-pret-etu01/Documents/LATTICE/méta/output/total_pivot_counts.json\", \"r\") as f:\n",
    "    pivot_totals = json.load(f)\n",
    "\n",
    "def detect_epoque(path):\n",
    "    if \"ep1\" in path:\n",
    "        return \"ep1\"\n",
    "    elif \"ep2\" in path:\n",
    "        return \"ep2\"\n",
    "    elif \"ep3\" in path:\n",
    "        return \"ep3\"\n",
    "    else:\n",
    "        raise ValueError(f\"Époque inconnue pour le chemin : {path}\")\n",
    "\n",
    "categories = {\n",
    "    \"s\": {\"output\": outputs_s, \"o\": o_s},\n",
    "    \"a\": {\"output\": outputs_a, \"o\": o_a},\n",
    "    \"y\": {\"output\": outputs_y, \"o\": o_y}\n",
    "}\n",
    "\n",
    "groupes = {\n",
    "    \"s\": [\"pain\", \"pains\"],\n",
    "    \"a\": [\"painful\"],\n",
    "    \"y\": [\"painfully\"]\n",
    "}\n",
    "\n",
    "def obtenir_total_lemma(epoque, lemmes):\n",
    "    return sum(pivot_totals.get(epoque, {}).get(l, 0) for l in lemmes)\n",
    "\n",
    "def analyser_categorie(nom_categorie, fichiers_dict):\n",
    "    lemmes_courants = groupes[nom_categorie]\n",
    "\n",
    "    for type_fichier, fichiers in fichiers_dict.items():\n",
    "        if not fichiers:\n",
    "            continue\n",
    "\n",
    "        dossier_sortie = os.path.dirname(fichiers[0])\n",
    "        chemin_sortie = os.path.join(dossier_sortie, f\"auswertung_{nom_categorie}_{type_fichier}.txt\")\n",
    "\n",
    "        with open(chemin_sortie, \"w\", encoding=\"utf-8\") as out:\n",
    "            for chemin_fichier in fichiers:\n",
    "                with open(chemin_fichier, \"r\", encoding=\"utf-8\") as f:\n",
    "                    lignes = [ligne.strip() for ligne in f if ligne.strip()]\n",
    "\n",
    "                if not lignes:\n",
    "                    out.write(f\"Fichier : {chemin_fichier}\\nAucun lemme trouvé.\\n\\n\")\n",
    "                    continue\n",
    "\n",
    "                ep = detect_epoque(chemin_fichier)\n",
    "                total_lemmas = obtenir_total_lemma(ep, lemmes_courants)\n",
    "                freq = Counter(lignes)\n",
    "                top_50 = freq.most_common(50)\n",
    "\n",
    "                out.write(f\"Fichier : {chemin_fichier}\\n\")\n",
    "                out.write(f\"Total pour {' + '.join(lemmes_courants)} dans {ep} : {total_lemmas}\\n\\n\")\n",
    "\n",
    "                df = pd.DataFrame(top_50, columns=[\"Lemme\", \"Fréquence\"])\n",
    "                df[\"Part / total pivot (%)\"] = df[\"Fréquence\"].apply(\n",
    "                    lambda x: round((x / total_lemmas) * 100, 2) if total_lemmas > 0 else \"N/A\"\n",
    "                )\n",
    "\n",
    "                tableau = tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\", showindex=False)\n",
    "                out.write(tableau + \"\\n\\n\" + \"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "for cat, fichiers_dict in categories.items():\n",
    "    analyser_categorie(cat, fichiers_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code pour tableaux avec filtre (be, were, is, are...), top 10 token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import json\n",
    "\n",
    "with open(\"/home/port-pret-etu01/Documents/LATTICE/méta/output/total_pivot_counts.json\", \"r\") as f:\n",
    "    pivot_totals = json.load(f)\n",
    "\n",
    "stop_words = {\n",
    "    \"is\", \"are\", \"be\", \"were\", \"'s\", \"been\", \"was\", \"-\", \"the\", \"the of\",\n",
    "    \"of\", \"some\", \"a\", \"the in\", \"a in\", \"such\", \"in\", \"any\", \".\", \"no\"\n",
    "}\n",
    "\n",
    "pronoun_keywords = {\n",
    "    \"his\", \"her\", \"our\", \"ours\", \"hers\", \"him\", \"she\", \"he\", \"we\", \"i\", \"my\",\n",
    "    \"thy\", \"their\", \"you\", \"your\", \"mine\", \"-\"\n",
    "}\n",
    "\n",
    "outputs_dict = {\n",
    "    \"s\": outputs_s,\n",
    "    \"a\": outputs_a,\n",
    "    \"y\": outputs_y\n",
    "}\n",
    "\n",
    "o_dict = {\n",
    "    \"s\": o_s,\n",
    "    \"a\": o_a,\n",
    "    \"y\": o_y\n",
    "}\n",
    "\n",
    "groupes = {\n",
    "    \"s\": [\"pain\", \"pains\"],\n",
    "    \"a\": [\"painful\"],\n",
    "    \"y\": [\"painfully\"]\n",
    "}\n",
    "\n",
    "TOP_N_FREQ_LIST = 400\n",
    "\n",
    "def detect_epoque(path):\n",
    "    if \"ep1\" in path:\n",
    "        return \"ep1\"\n",
    "    elif \"ep2\" in path:\n",
    "        return \"ep2\"\n",
    "    elif \"ep3\" in path:\n",
    "        return \"ep3\"\n",
    "    else:\n",
    "        raise ValueError(f\"Époque inconnue pour le chemin : {path}\")\n",
    "\n",
    "def obtenir_total_lemma(epoque, lemmes):\n",
    "    return sum(pivot_totals.get(epoque, {}).get(l, 0) for l in lemmes)\n",
    "\n",
    "def analyse_fichiers_filtrés(liste_fichiers, nom_categorie):\n",
    "    lemmes_courants = groupes[nom_categorie[-1]]\n",
    "    dossiers = {}\n",
    "\n",
    "    for fichier in liste_fichiers:\n",
    "        dossier = os.path.dirname(fichier)\n",
    "        if dossier not in dossiers:\n",
    "            dossiers[dossier] = []\n",
    "        dossiers[dossier].append(fichier)\n",
    "\n",
    "    for dossier, fichiers in dossiers.items():\n",
    "        chemin_sortie = os.path.join(dossier, f\"auswertung_filter_{nom_categorie}.txt\")\n",
    "        with open(chemin_sortie, \"w\", encoding=\"utf-8\") as out:\n",
    "            for fichier in fichiers:\n",
    "                ep = detect_epoque(fichier)\n",
    "                total_pivot = obtenir_total_lemma(ep, lemmes_courants)\n",
    "\n",
    "                with open(fichier, \"r\", encoding=\"utf-8\") as f:\n",
    "                    tokens = [ligne.strip() for ligne in f if ligne.strip()]\n",
    "\n",
    "                tokens_filtrés = []\n",
    "                for token in tokens:\n",
    "                    token_lc = token.lower().strip()\n",
    "                    if token_lc in stop_words:\n",
    "                        continue\n",
    "                    trouvé = None\n",
    "                    for pronom in pronoun_keywords:\n",
    "                        if token_lc == pronom or token_lc.endswith(\" \" + pronom) or token_lc.startswith(pronom + \" \") or f\" {pronom} \" in token_lc:\n",
    "                            trouvé = pronom\n",
    "                            break\n",
    "                    if trouvé:\n",
    "                        tokens_filtrés.append(trouvé)\n",
    "                    else:\n",
    "                        tokens_filtrés.append(token_lc)\n",
    "\n",
    "                tokens_stop = [t for t in tokens if t.lower() in stop_words]\n",
    "\n",
    "                total_tokens = len(tokens)\n",
    "                total_stop = len(tokens_stop)\n",
    "                total_après_filtrage = total_pivot - total_stop if total_pivot - total_stop > 0 else 1\n",
    "\n",
    "                out.write(f\"Fichier : {fichier}\\n\")\n",
    "                out.write(f\"Total pour {' + '.join(lemmes_courants)} dans {ep} : {total_pivot}\\n\")\n",
    "                out.write(f\"Nombre de stopwords : {total_stop} ({round((total_stop / total_pivot) * 100, 2) if total_pivot else 0}%)\\n\")\n",
    "                out.write(f\"Total après filtrage : {total_après_filtrage}\\n\\n\")\n",
    "\n",
    "                if not tokens_filtrés:\n",
    "                    out.write(\"Aucun token après filtrage.\\n\\n\")\n",
    "                    continue\n",
    "\n",
    "                freq = Counter(tokens_filtrés)\n",
    "                top_10 = freq.most_common(10)\n",
    "\n",
    "                df = pd.DataFrame(top_10, columns=[\"Token\", \"Fréquence\"])\n",
    "                df[\"Part / FILTRÉ (%)\"] = df[\"Fréquence\"].apply(lambda x: round((x / total_après_filtrage) * 100, 2))\n",
    "                df[\"Part / TOTAL Pivot (%)\"] = df[\"Fréquence\"].apply(lambda x: round((x / total_pivot) * 100, 2) if total_pivot > 0 else 0)\n",
    "\n",
    "                tableau = tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\", showindex=False)\n",
    "                out.write(tableau + \"\\n\\n\")\n",
    "\n",
    "                out.write(\"Liste complète des tokens les plus fréquents :\\n\")\n",
    "                top_freqs = freq.most_common(TOP_N_FREQ_LIST)\n",
    "                for token, count in top_freqs:\n",
    "                    out.write(f\"{token}: {count}\\n\")\n",
    "\n",
    "                out.write(\"\\n\" + \"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "for cat in [\"s\", \"a\", \"y\"]:\n",
    "    analyse_fichiers_filtrés(outputs_dict[cat], f\"output_{cat}\")\n",
    "    analyse_fichiers_filtrés(o_dict[cat], f\"o_{cat}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
